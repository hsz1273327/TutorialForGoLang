{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用golang连接常用的数据库和消息中间件\n",
    "\n",
    "写服务几乎必定会用到数据库和消息中间件,常用到的有:\n",
    "\n",
    "+ 数据库,用于保存和查询数据,最常见的是关系数据库\n",
    "+ 缓存,用于保存临时数据或多个服务共享数据,最常见的是redis\n",
    "+ 消息中间件,用于构造数据流,生产消费模式等,通常不对数据做处理,只是用于构造更加高性能高可维护性的结构件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关系数据库\n",
    "\n",
    "我们最常用的数据库还是关系数据库,他们都使用sql语言作为操作语言,应用最多的数据库产品就是`mysql`,`postgresql`和`sqlite`.一般写㐏也不直接连接使用SQL控制这些数据库,而是使用orm,这样虽然有一定的性能损失,但可以防止sql注入,同时代码也更加容易维护.我更推荐使用[xorm](https://xorm.io/zh/),这个库简单够用,同时提供一个周边工具可以把已有的数据库结构生成为对应的结构体.它还有个威力加强版[github.com/xormplus/xorm](https://www.kancloud.cn/xormplus/xorm/167077)定义了更多的操作,当然也更重些.\n",
    "\n",
    "使用orm更加适合多语言联合开发项目,向go基本是做服务端开发,python一般做原型开发或者mvp,dba则是直接使用客户端在命令行中操作数据库,数据分析数据挖掘的通常也是使用sql语句或者python连接数据库做处理取数据.可以看出go只是整个数据流中的一环中使用到,而且往往是做的写入操作,更加偏向于业务.相对于其他orm框架xorm最大的好处是\n",
    "\n",
    "1. 可以直接执行sql语句应付复杂请求\n",
    "2. 有工具直接导出已存在的数据库表到结构体,不需要围绕这个orm重新设计数据库.\n",
    "\n",
    "本部分例子在[这里](https://github.com/tutorialforgolang/go-server/tree/master/code/xorm_test)\n",
    "xorm需要安装如下3个部分\n",
    "\n",
    "+ orm本体\n",
    "\n",
    "```\n",
    "go get github.com/go-xorm/xorm\n",
    "```\n",
    "\n",
    "+ 扩展\n",
    "\n",
    "```\n",
    "go get github.com/xormplus/xorm\n",
    "```\n",
    "\n",
    "+ orm对应工具\n",
    "\n",
    "```\n",
    "go get github.com/go-xorm/cmd/xorm\n",
    "```\n",
    "\n",
    "+ 数据库驱动(选需要的装)\n",
    "\n",
    "    + Mysql: `github.com/go-sql-driver/mysql`\n",
    "    + Postgres: `github.com/lib/pq`\n",
    "    + SQLite: `github.com/mattn/go-sqlite3`\n",
    "    \n",
    "    \n",
    "使用的时候这么引入(本文以使用postgres做例子)\n",
    "\n",
    "```golang\n",
    "import (\n",
    "     _ \"github.com/lib/pq\"\n",
    "    \"github.com/go-xorm/xorm\"\n",
    ")\n",
    "```\n",
    "\n",
    "xorm使用`NewEngine`函数初始化一个数据库客户端对象\n",
    "```golang\n",
    "db, err := xorm.NewEngine(\"postgres\",\"postgres://postgres:postgres@localhost:5432/test?sslmode=disable\")\n",
    "```\n",
    "\n",
    "\n",
    "如果需要设置连接池的空闲数大小,可以使用`db.SetMaxIdleConns()`来实现\n",
    "\n",
    "\n",
    "如果需要设置最大打开连接数则可以使用`db.SetMaxOpenConns()`来实现\n",
    "\n",
    "\n",
    "我们也可以手动关闭这个数据库客户端对象\n",
    "```golang\n",
    "defer db.Close()\n",
    "```\n",
    "\n",
    "如果我们希望验证数据库操作,要打印出操作对应的sql语句,可以使用接口`ShowSQL(true)`\n",
    "```golang\n",
    "db.ShowSQL(true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义表结构\n",
    "\n",
    "xorm使用结构体定义表,我们可以在结构体中对应的字段上使用如下例的注解来细化定义表结构\n",
    "\n",
    "```\n",
    "`xorm:\"varchar(25) notnull unique 'usr_name'\"`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```golang\n",
    "type Goods struct {\n",
    "    Id    int `xorm:\"not null pk autoincr INTEGER\"`\n",
    "    Price uint\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据库中已有的表结构导出\n",
    "\n",
    "xorm相比起其他orm框架最大的优势就是他有工具支持将数据库中已有的表结构导出.这就让他有了支持先定义数据库再写业务逻辑这样工作流的能力.\n",
    "\n",
    "```bash\n",
    "xorm reverse [-s] driverName datasourceName tmplPath [generatedPath] [tableFilterReg]\n",
    "```\n",
    "\n",
    "+ `driverName`是数据库的名字,比如`postgres`\n",
    "+ `datasourceName`是数据库的连接配置字符串,比如`\"postgres://postgres:postgres@localhost:5432/test?sslmode=disable\"`\n",
    "+ `tmplPath`是模板所在的位置,通常在`GOPATH/src/github.com/go-xorm/cmd/xorm/templates/goxorm`\n",
    "+ `generatedPath`是将模板放在什么位置,比如在当前目录就设置`.`,不填就会生成在当前目录下的`model`文件夹下\n",
    "+ `tableFilterReg`则是用于筛选要导出的表名的re字符串.如果不填就会导出数据库中所有的表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 表操作\n",
    "\n",
    "常用的表操作有:\n",
    "\n",
    "+ 同步表`db.Sync2(...string|*struct)err`参数为一个或多个空的对应Struct的指针或表名字符串.Sync2函数将进行如下的同步操作:\n",
    "\n",
    "    + 自动检测和创建表,这个检测是根据表的名字\n",
    "    + 自动检测和新增表中的字段,这个检测是根据字段名,同时对表中多余的字段给出警告信息\n",
    "    + 自动检测,创建和删除索引和唯一索引,这个检测是根据索引的一个或多个字段名,而不根据索引名称.因此这里需要注意,如果在一个有大量数据的表中引入新的索引,数据库可能需要一定的时间来建立索引.\n",
    "    + 自动转换varchar字段类型到text字段类型,自动警告其它字段类型在模型和数据库之间不一致的情况.\n",
    "    + 自动警告字段的默认值,是否为空信息在模型和数据库之间不匹配的情况\n",
    "    \n",
    "    这是同步数据库的最简单方法,但由于其隐藏了大量细节,并不建议使用.通常这个用来代替`CreateTables`操作.\n",
    "\n",
    "+ 判断表是否存在`db.IsTableExist(...string|*struct) (bool,error)`参数为一个或多个空的对应Struct的指针或表名字符串.\n",
    "\n",
    "+ 判断表是否是空的`db.IsTableEmpty(...string|*struct) (bool,error)`参数为一个或多个空的对应Struct的指针或表名字符串.\n",
    "\n",
    "+ 创建表`db.CreateTables(...string|*struct) error`参数为一个或多个空的对应Struct的指针或表名字符串\n",
    "\n",
    "+ 删除表`db.DropTables(...string|*struct) error`参数为一个或多个空的对应Struct的指针或表名字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```golang\n",
    "func sync_table() {\n",
    "    db, err := xorm.NewEngine(\"postgres\",\"postgres://postgres:postgres@localhost:5432/test?sslmode=disable\")\n",
    "    if err != nil {\n",
    "        fmt.Printf(\"%v\", err)\n",
    "    } else {\n",
    "        defer db.Close()\n",
    "        db.ShowSQL(true)\n",
    "        var ok bool\n",
    "        ok, err = db.IsTableExist(\"goods\")\n",
    "        if err != nil{\n",
    "            fmt.Println(\"table goods IsTableExist error\", err)\n",
    "        }else{\n",
    "            fmt.Println(\"table goods is exist :%v\", ok)\n",
    "            err = db.Sync2(&Goods{})\n",
    "            if err != nil{\n",
    "                fmt.Println(\"table goods Sync2 error\", err)\n",
    "            }else{\n",
    "                ok, err = db.IsTableExist(\"goods\")\n",
    "                if err != nil{\n",
    "                    fmt.Println(\"table goods IsTableExist error\", err)\n",
    "                }else{\n",
    "                    fmt.Println(\"table goods is exist :%v\", ok)\n",
    "                }\n",
    "            }\n",
    "                \n",
    "        }  \n",
    "    }\n",
    "}\n",
    "sync_table()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写操作\n",
    "\n",
    "> 插入数据\n",
    "\n",
    "插入数据可以一次插入一条也可以一次插入多条\n",
    "\n",
    "+ 插入一条\n",
    "\n",
    "```golang\n",
    "goods := &Goods{\n",
    "\t\tId:    0,\n",
    "\t\tPrice: 4,\n",
    "\t}\n",
    "\n",
    "affected, err := db.Insert(goods)\n",
    "\n",
    "```\n",
    "\n",
    "+ 插入多条\n",
    "\n",
    "```golang\n",
    "goods := []*Goods{{\n",
    "\t\tId:    1,\n",
    "\t\tPrice: 3,\n",
    "\t}, {\n",
    "\t\tId:    2,\n",
    "\t\tPrice: 2,\n",
    "\t}, {\n",
    "\t\tId:    3,\n",
    "\t\tPrice: 1,\n",
    "\t},\n",
    "\t}\n",
    "\n",
    "affected, err := db.Insert(goods)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 更新数据\n",
    "\n",
    "更新数据有两种方式:\n",
    "\n",
    "+ 指定列\n",
    "\n",
    "```golang\n",
    "good := new(Goods)\n",
    "good.Price = 15\n",
    "affected, err := db.Id(1).Cols(\"price\").Update(good)\n",
    "```\n",
    "\n",
    "+ 指定表后传入map,在map中指定要更新的列\n",
    "\n",
    "```golang\n",
    "affected, err := db.Table(new(Goods)).Id(2).Update(map[string]interface{}{\"price\":20})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 删除数据\n",
    "\n",
    "直接使用`Delete`接口就好\n",
    "\n",
    "```golang\n",
    "affected, err := db.Where(\"id >?\", 2).Delete(new(Goods))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 直接执行sql语句\n",
    "\n",
    "```golang\n",
    "sql = \"update goods set price=? where id=?\"\n",
    "res, err := engine.Exec(sql, 40, 1) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读操作\n",
    "\n",
    "> 查询数据\n",
    "\n",
    "xorm有几个方法用于查询数据,这几个方法需要在语句最后调用作为一个链式查询的终结.他们是:\n",
    "\n",
    "+ `Get` 查询单条数据,返回的是bool值,找到的对象会被存入传入的对象: \n",
    "\n",
    "```golang\n",
    "good := new(Goods)\n",
    "has, err := db.Id(id).Get(good)\n",
    "```\n",
    "\n",
    "+ `Exist` 查询记录是否存在,它的性能比`Get`好: \n",
    "\n",
    "```golang\n",
    "good := new(Goods)\n",
    "has, err := db.Exist(goodExist)\n",
    "```\n",
    "\n",
    "+ `Find`查询多条数据使用,第一个参数为slice的指针或Map指针,即为查询后返回的结果,如果是map的指针,那么map的key为数据的主键,这种方式无法使用复合主键;第二个参数可选,为查询的条件struct的指针: \n",
    "\n",
    "```golang\n",
    "goods := make([]Goods,0)\n",
    "err := db.Find(&goods)\n",
    "```\n",
    "\n",
    "+ `Iterate`提供逐条执行查询到的记录的方法,他所能使用的条件和Find方法完全相同,但最后一位参数为一个回调函数`func (int,interface{})error`,回调函数的第二个参数就是一条数据,但需要将对象转换成对应的类型:\n",
    "\n",
    "```golang\n",
    "err := db.Where(\"id >?\", 1).Iterate(new(Goods), func(i int, bean interface{}) error {\n",
    "\t\tgood := bean.(*Goods)\n",
    "\t\tfmt.Println(\"good price:\", good.Price)\n",
    "\t\treturn nil\n",
    "\t})\n",
    "```\n",
    "\n",
    "+ `Rows`Iterate方法类似,提供逐条执行查询到的记录的方法,不过Rows更加灵活好用:\n",
    "\n",
    "```golang\n",
    "good := new(Goods)\n",
    "rows, err := engine.Where(\"id >?\", 1).Rows(good)\n",
    "if err != nil {\n",
    "}\n",
    "defer rows.Close()\n",
    "for rows.Next() {\n",
    "    err = rows.Scan(good)\n",
    "    if err != nil{\n",
    "        fmt.Println(\"error:\",err)\n",
    "    }else{\n",
    "        fmt.Println(\"good price:\",good.Price)\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "+ `Count`统计数据数量使用,Count方法的参数为struct的指针并且成为查询条件.\n",
    "\n",
    "```golang\n",
    "count, err := db.Where(\"id >?\", 1).Count(new(Goods))\n",
    "```\n",
    "\n",
    "\n",
    "+ `FindAndCount` 结合Count和Find操作\n",
    "\n",
    "```golang\n",
    "goods := make([]Goods,0)\n",
    "counts, err := engine.FindAndCount(&goods)\n",
    "```\n",
    "\n",
    "+ `Sum`/`SumInt`用于求和\n",
    "\n",
    "```golang\n",
    "total, err := db.Where(\"id >?\", 1).Sum(new(Goods), \"price\")\n",
    "```\n",
    "\n",
    "这些方法之间都可以插入一些条件语句用于确定查询范围,比如`Where`,`Join`,或者直接使用`Sql`直接使用sql语句筛选.主要是:\n",
    "\n",
    "\n",
    "+ `SQL(string, …interface{})`直接写出要执行的sql语句\n",
    "\n",
    "+ `Select(string)`直接写出sql语句中select部分的字符串\n",
    "\n",
    "+ `Where(string, …interface{})`直接写出sql语句中where部分的字符串\n",
    "\n",
    "+ `Join(string,interface{},string)`;连接两张表\n",
    "+ `GroupBy(string)`聚合操作字符串\n",
    "+ `Having(string)` having操作的字符串\n",
    "\n",
    "+ `AllCols()`/`Cols(…string)`/`Omit(…string)`指定全部列/指定特定的列/指定除特定列外的所有列\n",
    "\n",
    "+ `Table(nameOrStructPtr interface{})`指定表\n",
    "+ `Alias(string)`为表取别名,用于在后面的条件中表达\n",
    "\n",
    "+ `OrderBy(string)`以字段作为排序的条件\n",
    "+ `Asc(…string)`/`Desc(…string)`结果正序/逆序排列\n",
    "\n",
    "+ `Id()`限定主键作为查询条件\n",
    "\n",
    "+ `And(string, …interface{})`表达并列条件\n",
    "+ `Or(interface{}, …interface{})`表达或条件\n",
    "\n",
    "+ `Limit(int, …int)`/`Top(int)`限制结果数量\n",
    "+ `Distinct(…string)`去重\n",
    "+ `In(string, …interface{})`字段取值所在范围\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 直接执行sql语句查询数据\n",
    "\n",
    "xorm提供了不依赖于定义好的结构体直接查询sql语句的接口`Query(sql)`,其返回值是`[]map[string][]byte`类型我们需要按需要将其值转化成我们可以用的值\n",
    "\n",
    "```golang\n",
    "sql := \"select * from goods\"\n",
    "results, err := db.Query(sql)\n",
    "if err != nil {\n",
    "    fmt.Println(\"error:\", err)\n",
    "} else {\n",
    "    for _, v := range results {\n",
    "        fmt.Printf(\"good id:%v;\\nprice:%v\\n\", string(v[\"id\"]), string(v[\"price\"]))\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "类似的还有接口\n",
    "\n",
    "+ `QueryString`,其返回值为`[]map[string]string`\n",
    "+ `QueryInterface`,其返回值为`[]map[string]interface{}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单事务支持\n",
    "\n",
    "xorm支持简单事务操作,使用`Session`会话对象代替数据库客户端对象,并配合上事务特有接口即可\n",
    "\n",
    "+ `Begin()`开始事务\n",
    "+ `Rollback()`事务回退\n",
    "+ `Commit()`提交事务\n",
    "\n",
    "每次会话创建后需要使用`Close()`接口关闭,一个更好的方式是事务的创建和定义直接使用函数包装,借助`defer`关键字关闭会话防止业务复杂了遗漏关闭操作.\n",
    "需要注意一次事务必须定义在一个协程中.\n",
    "\n",
    "```golang\n",
    "func simple_transact(db *xorm.Engine) {\n",
    "\tfmt.Println(\"--------------------simple transact---------------------\")\n",
    "\tsession := db.NewSession()\n",
    "\tdefer session.Close()\n",
    "\t// add Begin() before any action\n",
    "\terr := session.Begin()\n",
    "\tgood := Goods{Id: 5, Price: 70}\n",
    "\t_, err = session.Insert(&good)\n",
    "\tif err != nil {\n",
    "\t\tsession.Rollback()\n",
    "\t\tfmt.Println(\"error:\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "\tgood2 := Goods{Price: 40}\n",
    "\t_, err = session.Where(\"id = ?\", 2).Update(&good2)\n",
    "\tif err != nil {\n",
    "\t\tsession.Rollback()\n",
    "\t\tfmt.Println(\"error:\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "\n",
    "\t_, err = session.Exec(\"delete from goods where id = ?\", 2)\n",
    "\tif err != nil {\n",
    "\t\tsession.Rollback()\n",
    "\t\tfmt.Println(\"error:\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "\n",
    "\t// add Commit() after all actions\n",
    "\terr = session.Commit()\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"error:\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对业务支持\n",
    "\n",
    "> 一致性缓存\n",
    "\n",
    "xorm可以使用服务内存来实现一致性缓存功能,不过默认并没有开启,要开启缓存，需要在db创建完后进行配置,\n",
    "\n",
    "```\n",
    "cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000)\n",
    "db.SetDefaultCacher(cacher)\n",
    "```\n",
    "这个缓存的设置为使用服务内存创建,并且每个struc(表)缓存1000条数据.要为不同表设定不同的缓存可以使用\n",
    "\n",
    "```golang\n",
    "db.MapCacher(&good, cacher)\n",
    "```\n",
    "\n",
    "不过需要特别注意不适用缓存或者需要手动编码的地方:\n",
    "\n",
    "1. 当使用了Distinct,Having,GroupBy方法将不会使用缓存\n",
    "\n",
    "2. 在Get或者Find时使用了Cols,Omit方法,则在开启缓存后此方法无效,系统仍旧会取出这个表中的所有字段.\n",
    "\n",
    "3. 在使用Exec方法执行了方法之后可能会导致缓存与数据库不一致的地方.因此如果启用缓存应尽量避免使用Exec.如果必须使用,则需要在使用了Exec之后调用ClearCache手动做缓存清除的工作.比如\n",
    "```golang\n",
    "db.Exec(\"update user set name = ? where id = ?\", \"xlw\", 1)\n",
    "db.ClearCache(new(User))\n",
    "```\n",
    "\n",
    "使用服务内存作为缓存是最简单的方式,但它不利于多节点共享缓存数据,我们可以使用官方的扩展包[github.com/go-xorm/cachestore](https://github.com/go-xorm/cachestore/blob/master/README_zh-CN.md)来利用redis实现缓存\n",
    "\n",
    "```golang\n",
    "\n",
    "configs := map[string]string{\n",
    "    \"conn\":\"localhost:6379\",\n",
    "    \"key\":\"default\", // the collection name of redis for cache adapter.\n",
    "}\n",
    "ccStore := cachestore.NewRedisCache(configs)\n",
    "cacher := xorm.NewLRUCacher(ccStore, 99999999)\n",
    "db.SetDefaultCacher(cacher)\n",
    "```\n",
    "\n",
    "\n",
    "> 操作钩子\n",
    "\n",
    "xorm有两种方式定义钩子:\n",
    "\n",
    "1. 在为结构体定义对应名字的实例方法,这种方式适合用于定义每次都需要做的操作\n",
    "\n",
    "    可以使用的钩子名有:\n",
    "\n",
    "    + `BeforeInsert()`在将此实例插入到数据库之前执行\n",
    "    + `AfterInsert()`在将此实例成功插入到数据库之后执行\n",
    "    + `BeforeUpdate()`在将此实例更新到数据库之前执行\n",
    "    + `AfterUpdate()`在将此实例成功更新到数据库之后执行\n",
    "    + `BeforeDelete()`在将此实例对应的条件数据从数据库删除之前执行\n",
    "    + `AfterDelete()`在将此实例对应的条件数据成功从数据库删除之后执行\n",
    "    + `BeforeSet(name string, cell xorm.Cell)`在 Get 或 Find 方法中，当数据已经从数据库查询出来,而在设置到结构体之前调用,name为数据库字段名称,cell为数据库中的字段值.\n",
    "    + `AfterSet(name string, cell xorm.Cell)`在 Get 或 Find 方法中，当数据已经从数据库查询出来,而在设置到结构体之后调用,name为数据库字段名称,cell为数据库中的字段值.\n",
    "    \n",
    "    ```golang\n",
    "    type Goods struct {\n",
    "        Id    int `xorm:\"not null pk autoincr INTEGER\"`\n",
    "        Price uint\n",
    "    }\n",
    "\n",
    "    func (self *Goods) BeforeInsert() {\n",
    "        fmt.Println(\"before insert good %v\", self.Id)\n",
    "    }\n",
    "\n",
    "    func (self *Goods) AfterInsert() {\n",
    "        fmt.Println(\"after insert good %v\", self.Id)\n",
    "    }\n",
    "\n",
    "    func (self *Goods) BeforeUpdate() {\n",
    "        fmt.Println(\"before update good %v\", self.Id)\n",
    "    }\n",
    "\n",
    "    func (self *Goods) AfterUpdate() {\n",
    "        fmt.Println(\"after update good %v\", self.Id)\n",
    "    }\n",
    "\n",
    "    func (self *Goods) BeforeDelete() {\n",
    "        fmt.Println(\"after delete good %v\", self.Id)\n",
    "    }\n",
    "    func (self *Goods) AfterDelete() {\n",
    "        fmt.Println(\"after delete good %v\", self.Id)\n",
    "    }\n",
    "\n",
    "    func (self *Goods) BeforeSet(name string, cell xorm.Cell) {\n",
    "        fmt.Println(\"before set %v as %v\", name, *cell)\n",
    "    }\n",
    "    func (self *Goods) AfterSet(name string, cell xorm.Cell) {\n",
    "        fmt.Println(\"after set %v as %v\", name, *cell)\n",
    "    }\n",
    "    ```\n",
    "\n",
    "2. 在执行语句前使用`Before(beforeFunc interface{})`/`After(afterFunc interface{})`定义操作,其回调函数的签名为`func(bean interface{})`也就是获得对象的实例.\n",
    "\n",
    "    ```golang\n",
    "    has, err := db.After(func(bean interface{}) {\n",
    "        temp := bean.(*Goods)\n",
    "        fmt.Println(\"after get select get table instance: \", temp)\n",
    "    }).Id(3).Get(good)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时序数据库influxdb\n",
    "\n",
    "[influxdb](https://docs.influxdata.com/influxdb/v1.7/)本身就是golang写的,它有官方的go语言客户端[github.com/influxdata/influxdb1-client/v2](https://github.com/influxdata/influxdb1-client)\n",
    "\n",
    "他的引用方式比较奇葩,这主要是go mod系统的锅:\n",
    "\n",
    "```golang\n",
    "import(\n",
    "    _ \"github.com/influxdata/influxdb1-client\" // this is important because of the bug in go mod\n",
    "    influx \"github.com/influxdata/influxdb1-client/v2\"\n",
    ")\n",
    "```\n",
    "\n",
    "influxdb只有3个操作:\n",
    "\n",
    "1. 连接服务\n",
    "\n",
    "```golang\n",
    "client, err := influx.NewHTTPClient(client.HTTPConfig{\n",
    "    Addr: \"http://localhost:8086\",\n",
    "})\n",
    "if err != nil {\n",
    "    fmt.Println(\"Error creating InfluxDB Client: \", err.Error())\n",
    "}\n",
    "defer c.Close()\n",
    "```\n",
    "\n",
    "2. 发出请求\n",
    "\n",
    "```golang\n",
    "func query_point() {\n",
    "\t...\n",
    "\tq := influx.NewQuery(\"SELECT count(*) FROM cpu_usage\", \"BumbleBeeTuna\", \"s\")\n",
    "\tif response, err := client.Query(q); err == nil && response.Error() == nil {\n",
    "\t\tfmt.Println(response.Results)\n",
    "\t}\n",
    "}\n",
    "```\n",
    "\n",
    "3. 写入数据\n",
    "\n",
    "```golang\n",
    "func randomWrite() {\n",
    "    ...\n",
    "    bp, _ := influx.NewBatchPoints(influx.BatchPointsConfig{\n",
    "        Database:  \"BumbleBeeTuna\",\n",
    "        Precision: \"s\",\n",
    "    })\n",
    "    tags := map[string]string{\"cpu\": \"cpu-total\"}\n",
    "    fields := map[string]interface{}{\n",
    "        \"idle\":   10.1,\n",
    "        \"system\": 53.3,\n",
    "        \"user\":   46.6,\n",
    "    }\n",
    "    pt, err := influx.NewPoint(\"cpu_usage\", tags, fields, time.Now())\n",
    "    if err != nil {\n",
    "        fmt.Println(\"Error: \", err.Error())\n",
    "    }\n",
    "    bp.AddPoint(pt)\n",
    "    err = client.Write(bp)\n",
    "    if err != nil {\n",
    "        fmt.Println(\"Error: \", err.Error())\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "本例代码在[这里](https://github.com/tutorialforgolang/go-server/tree/master/code/influxdb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最常用的缓存Redis\n",
    "\n",
    "实际上分布式缓存有很多选择,但恐怕最有通用性的就是redis了,我们一般使用[github.com/go-redis/redis](https://github.com/go-redis/redis)这个库来连接redis.\n",
    "\n",
    "本部分例子在[这里](https://github.com/tutorialforgolang/go-server/tree/master/code/redis_test)\n",
    "\n",
    "### 建立连接\n",
    "\n",
    "通常redis有两种服务端:\n",
    "\n",
    "1. 单机`NewClient(*redis.Options)`\n",
    "\n",
    "```golang\n",
    "opt, err  := redis.ParseURL(\"redis://localhost:6379/1\")\n",
    "if err != nil {\n",
    "   panic(err)\n",
    "}\n",
    "client:=redis.NewClient(opt)\n",
    "```\n",
    "\n",
    "2. 集群`NewClusterClient(*redis.ClusterOptions)`\n",
    "\n",
    "```golang\n",
    "redisdb := redis.NewClusterClient(&redis.ClusterOptions{\n",
    "\tAddrs: []string{\":7000\", \":7001\", \":7002\", \":7003\", \":7004\", \":7005\"},\n",
    "})\n",
    "```\n",
    "本文将以单机为例,因为像亚马逊,阿里云这些服务提供商已经将集群封装成了单机接口.\n",
    "\n",
    "\n",
    "### 使用命令\n",
    "\n",
    "这个包已经封装了几乎全部的redis命令.\n",
    "\n",
    "```golang\n",
    "val, err := client.Get(key).Result()\n",
    "if err != nil {\n",
    "    if err == redis.Nil {\n",
    "        fmt.Printf(\"key %v 不存在\\n\", key)\n",
    "    } else {\n",
    "        fmt.Println(\"error:\", err)\n",
    "    }\n",
    "} else {\n",
    "    fmt.Println(\"key\", key, val)\n",
    "}\n",
    "```\n",
    "\n",
    "如果不确定要用的命令是否已经有封装,可以直接使用`Do()`接口直接发出命令\n",
    "\n",
    "\n",
    "```golang\n",
    "val, err := client.Do(\"get\", key).String()\n",
    "```\n",
    "\n",
    "`,`用于分隔命令中各段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 事务\n",
    "\n",
    "redis使用`pipline`来定义事务.\n",
    "\n",
    "```golang\n",
    "func incr_pipeline(client *redis.Client) {\n",
    "\tpipe := client.Pipeline()\n",
    "\n",
    "\tincr := pipe.Incr(\"pipeline_counter\")\n",
    "\tpipe.Expire(\"pipeline_counter\", time.Hour)\n",
    "\t_, err := pipe.Exec()\n",
    "\tfmt.Println(incr.Val(), err)\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见消息中间件\n",
    "\n",
    "消息中间件一般就是两个功能\n",
    "\n",
    "1. 队列(生产消费模式)\n",
    "2. 广播(广播模式)\n",
    "\n",
    "队列一般用于生产消费模式,用于将并发的任务串行化;广播则用于在范围内同时通知多个组件,常用于并行化处理数据.\n",
    "\n",
    "接下来的例子中本文将使用下面3种工具实现一个分发随机数求平方和的功能.其中会用到这两种模式:\n",
    "\n",
    "+ 生产消费模式: 生产者向sourceQ队列发送数据,消费者从sourceQ队列取数据,消费者计算完成平方后将结果放入队列resultQ,生产者接收resultQ队列中的结果更新累加结果并打印在标准输出中.\n",
    "+ 广播模式: 生产者在收到KeyboardInterrupt错误时向频道exitCh发出消息,消费者订阅频道exitCh,当收到消息时退出."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用redis做消息中间件\n",
    "\n",
    "redis因为数双端列表和pub/sub模式,而且实时性非常好,所以在允许信息丢失的情况下经常有人用它做消息中间件,比如著名的任务队列工具celery及其衍生工具就常用redis做broker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 双端列表做消息队列\n",
    "\n",
    "对应的操作包括\n",
    "\n",
    "+ `EXISTS key`判断key是否存在\n",
    "+ `TYPE key`用于获取key对应数据结构,必须得是`list`\n",
    "+ `lpush key values`将消息从左侧推入key对应的list中\n",
    "+ `lpushx key values`将消息从左侧推入key对应的一个已经存在的list中\n",
    "+ `rpop key`从右侧取出key对应list中第一个值\n",
    "\n",
    "> pub/sub做广播\n",
    "\n",
    "对应的操作\n",
    "\n",
    "+ 发布广播到信道\n",
    "\n",
    "```golang\n",
    "err := redisdb.Publish(\"mychannel1\", \"hello\").Err()\n",
    "```\n",
    "\n",
    "+ 订阅监听\n",
    "\n",
    "```golang\n",
    "pubsub := client.Subscribe(\"mychannel1\")\n",
    "\n",
    "ch := pubsub.Channel()\n",
    "\n",
    "// Consume messages.\n",
    "for msg := range ch {\n",
    "    fmt.Println(msg.Channel, msg.Payload)\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 例子实现:\n",
    "\n",
    "+ 共用的推送代码\n",
    "\n",
    "```golang\n",
    "package push\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\n",
    "\t\"github.com/go-redis/redis\"\n",
    ")\n",
    "\n",
    "func Push(client *redis.Client, Q string, value string) error {\n",
    "\tisExists, err1 := client.Exists(Q).Result()\n",
    "\tif err1 != nil {\n",
    "\t\tif err1 == redis.Nil {\n",
    "\t\t\tfmt.Printf(\"key %v 不存在\\n\", Q)\n",
    "\t\t} else {\n",
    "\t\t\tfmt.Println(\"error:\", err1)\n",
    "\t\t}\n",
    "\t\treturn err1\n",
    "\t}\n",
    "\n",
    "\ttype_, err2 := client.Type(Q).Result()\n",
    "\tif err2 != nil {\n",
    "\t\tif err2 == redis.Nil {\n",
    "\t\t\tfmt.Printf(\"queue %v 不存在\\n\", Q)\n",
    "\t\t} else {\n",
    "\t\t\tfmt.Println(\"error:\", err2)\n",
    "\t\t}\n",
    "\t\treturn err2\n",
    "\t}\n",
    "\tif isExists > 0 && type_ == \"list\" {\n",
    "\t\t_, err := client.LPushX(Q, value).Result()\n",
    "\t\tif err != nil {\n",
    "\t\t\tif err == redis.Nil {\n",
    "\t\t\t\tfmt.Printf(\"queue %v 不存在\\n\", Q)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tfmt.Println(\"error:\", err)\n",
    "\t\t\t}\n",
    "\t\t\treturn err\n",
    "\t\t}\n",
    "\t\tfmt.Printf(\"send %v to %v\\n\", value, Q)\n",
    "\t\treturn nil\n",
    "\t}\n",
    "\t_, err := client.Del(Q).Result()\n",
    "\tif err != nil {\n",
    "\t\tif err == redis.Nil {\n",
    "\t\t\tfmt.Printf(\"key %v 不存在\\n\", Q)\n",
    "\t\t} else {\n",
    "\t\t\tfmt.Println(\"error:\", err)\n",
    "\t\t}\n",
    "\t\treturn err\n",
    "\t}\n",
    "\t_, err = client.LPush(Q, value).Result()\n",
    "\tif err != nil {\n",
    "\t\tif err == redis.Nil {\n",
    "\t\t\tfmt.Printf(\"key %v 不存在\\n\", Q)\n",
    "\t\t} else {\n",
    "\t\t\tfmt.Println(\"error:\", err)\n",
    "\t\t}\n",
    "\t\treturn err\n",
    "\t}\n",
    "\tfmt.Printf(\"send %v to %v\\n\", value, Q)\n",
    "\treturn nil\n",
    "}\n",
    "```\n",
    "\n",
    "将消息推送到队列中操作在生产者和消费者两端都是一样的,需要改变的只是队列的名字和要推送的值而已,因此将其抽象出来单独作为一个子模块.\n",
    "\n",
    "\n",
    "+ 生产者\n",
    "\n",
    "```golang\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"math/rand\"\n",
    "\t\"os\"\n",
    "\t\"os/signal\"\n",
    "\t\"redis_test/push\"\n",
    "\t\"strconv\"\n",
    "\t\"sync\"\n",
    "\t\"time\"\n",
    "\n",
    "\t\"github.com/go-redis/redis\"\n",
    ")\n",
    "\n",
    "var c chan os.Signal\n",
    "var c1 chan os.Signal\n",
    "var wg sync.WaitGroup\n",
    "\n",
    "func producer(client *redis.Client, sourceQ string, exitCh string) {\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-c:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"Producer | get exit signal\", s)\n",
    "\t\t\tclient.Publish(exitCh, \"Exit\")\n",
    "\t\t\tbreak Loop\n",
    "\t\tdefault:\n",
    "\t\t}\n",
    "\t\tdata := rand.Int31n(400)\n",
    "\t\terr := push.Push(client, sourceQ, strconv.Itoa(int(data)))\n",
    "\t\tif err != nil {\n",
    "\t\t\tfmt.Println(\"err:\", err)\n",
    "\t\t}\n",
    "\t\ttime.Sleep(1 * time.Second)\n",
    "\t}\n",
    "\tfmt.Println(\"Producer |  exit\")\n",
    "\twg.Done()\n",
    "}\n",
    "\n",
    "func collector(client *redis.Client, resultQ string) error {\n",
    "\tvar sum int64 = 0\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-c1:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"collector | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\t\tdefault:\n",
    "\t\t}\n",
    "\t\tisExists, err1 := client.Exists(resultQ).Result()\n",
    "\t\tif err1 != nil {\n",
    "\t\t\tif err1 == redis.Nil {\n",
    "\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", resultQ)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tfmt.Println(\"collector error:\", err1)\n",
    "\t\t\t}\n",
    "\t\t\treturn err1\n",
    "\t\t}\n",
    "\t\ttype_, err2 := client.Type(resultQ).Result()\n",
    "\t\tif err2 != nil {\n",
    "\t\t\tif err2 == redis.Nil {\n",
    "\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", resultQ)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tfmt.Println(\"collector error:\", err2)\n",
    "\t\t\t}\n",
    "\t\t\treturn err2\n",
    "\t\t}\n",
    "\t\tif isExists > 0 && type_ == \"list\" {\n",
    "\t\t\tdata, err3 := client.RPop(resultQ).Result()\n",
    "\t\t\tif err3 != nil {\n",
    "\t\t\t\tif err3 == redis.Nil {\n",
    "\t\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", resultQ)\n",
    "\t\t\t\t\ttime.Sleep(1 * time.Second)\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tfmt.Println(\"collector error:\", err3)\n",
    "\t\t\t\t}\n",
    "\t\t\t\treturn err3\n",
    "\t\t\t}\n",
    "\t\t\tfmt.Println(\"collector received data: \", data)\n",
    "\t\t\td, err := strconv.ParseInt(data, 10, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tfmt.Println(\"collector err:\", err)\n",
    "\t\t\t}\n",
    "\t\t\tsum += d\n",
    "\t\t\tfmt.Println(\"collector get sum \", sum)\n",
    "\t\t} else {\n",
    "\t\t\ttime.Sleep(1 * time.Second)\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"collector | exit\")\n",
    "\twg.Done()\n",
    "\treturn nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\topt, err := redis.ParseURL(\"redis://localhost:6379/1\")\n",
    "\tif err != nil {\n",
    "\t\tpanic(err)\n",
    "\t}\n",
    "\tclient := redis.NewClient(opt)\n",
    "\tsourceQ := \"sourceQ\"\n",
    "\tresultQ := \"resultQ\"\n",
    "\texitCh := \"exitCh\"\n",
    "\n",
    "\tc = make(chan os.Signal, 1)\n",
    "\tc1 = make(chan os.Signal, 1)\n",
    "\tsignal.Notify(c, os.Interrupt, os.Kill)\n",
    "\tsignal.Notify(c1, os.Interrupt, os.Kill)\n",
    "\twg.Add(1)\n",
    "\tgo collector(client, resultQ)\n",
    "\twg.Add(1)\n",
    "\tgo producer(client, sourceQ, exitCh)\n",
    "\twg.Wait()\n",
    "}\n",
    "```\n",
    "\n",
    "生产者部分我们构造两个协程--生产器`producer`用于每隔1s向队列中发送要处理的数据,和收集器`collector`用于收集运算结果.同时使用`sync.WaitGroup`阻塞主go协程,同时等待两个go协程执行完毕退出.于此同时主协程监听退出信号(ctr+c),利用channel向两个go协程发送退出指令.当有退出信号时,生产器会将向redis中的退出信道发出一条广播消息.\n",
    "\n",
    "+ 消费者\n",
    "\n",
    "```golang\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"redis_test/push\"\n",
    "\t\"strconv\"\n",
    "\t\"time\"\n",
    "\n",
    "\t\"github.com/go-redis/redis\"\n",
    ")\n",
    "\n",
    "func get_result(client *redis.Client, sourceQ string, resultQ string) error {\n",
    "\tfmt.Printf(\"get_result running\\n\")\n",
    "\n",
    "\tfor {\n",
    "\t\tisExists, err1 := client.Exists(sourceQ).Result()\n",
    "\t\tif err1 != nil {\n",
    "\t\t\tif err1 == redis.Nil {\n",
    "\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", sourceQ)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tfmt.Println(\"error:\", err1)\n",
    "\t\t\t}\n",
    "\t\t\treturn err1\n",
    "\t\t}\n",
    "\t\ttype_, err2 := client.Type(sourceQ).Result()\n",
    "\t\tif err2 != nil {\n",
    "\t\t\tif err2 == redis.Nil {\n",
    "\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", sourceQ)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tfmt.Println(\"error:\", err2)\n",
    "\t\t\t}\n",
    "\t\t\treturn err2\n",
    "\t\t}\n",
    "\t\tif isExists > 0 && type_ == \"list\" {\n",
    "\t\t\tdata, err3 := client.RPop(sourceQ).Result()\n",
    "\t\t\tif err3 != nil {\n",
    "\t\t\t\tif err3 == redis.Nil {\n",
    "\t\t\t\t\tfmt.Printf(\"key %v 不存在\\n\", resultQ)\n",
    "\t\t\t\t\ttime.Sleep(1 * time.Second)\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tfmt.Println(\"error:\", err3)\n",
    "\t\t\t\t}\n",
    "\t\t\t\treturn err3\n",
    "\t\t\t}\n",
    "\t\t\tfmt.Println(\"received data: \", data)\n",
    "\t\t\td, err := strconv.ParseInt(data, 10, 32)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tfmt.Println(\"err:\", err)\n",
    "\t\t\t} else {\n",
    "\t\t\t\tresult := d * d\n",
    "\t\t\t\tpush.Push(client, resultQ, strconv.Itoa(int(result)))\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\topt, err := redis.ParseURL(\"redis://localhost:6379/1\")\n",
    "\tif err != nil {\n",
    "\t\tpanic(err)\n",
    "\t}\n",
    "\tclient := redis.NewClient(opt)\n",
    "\tsourceQ := \"sourceQ\"\n",
    "\tresultQ := \"resultQ\"\n",
    "\texitCh := \"exitCh\"\n",
    "\tgo get_result(client, sourceQ, resultQ)\n",
    "\tpubsub := client.Subscribe(exitCh)\n",
    "\tdefer pubsub.Close()\n",
    "\tch := pubsub.Channel()\n",
    "\tfor msg := range ch {\n",
    "\t\tfmt.Println(msg.Channel, msg.Payload)\n",
    "\t\tif msg.Payload == \"Exit\" {\n",
    "\t\t\treturn\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "消费者端只需要定时监听资源队列,有新数据就处理,处理完后丢到结果队列即可."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用kafka做消息中间件\n",
    "\n",
    "\n",
    "kafka是一个追求高吞吐的分布式消息队列.和redis比较是另一个极端,几乎是为复杂而生:\n",
    "\n",
    "+ 天生支持分布式,并且它必须依赖zonekeeper维护集群一致性.\n",
    "+ 天生持久化,硬盘允许情况下保留所有消息.\n",
    "\n",
    "kafka使用groupid来区分监听端是一次性消耗还是广播,当监听端使用不同的groupid时它相当于做广播,而使用相同的groupid时它相当于做生产消费的队列.\n",
    "\n",
    "我们使用[gopkg.in/confluentinc/confluent-kafka-go.v1/kafka](https://github.com/confluentinc/confluent-kafka-go)包来连接kafka,注意这个包无法在windows下安装使用\n",
    "\n",
    "\n",
    "代码[在这里](https://github.com/tutorialforgolang/go-server/tree/master/code/broker_test/kafka_broker)\n",
    "其操作是:\n",
    "\n",
    "+ 生产端\n",
    "\n",
    "```golang\n",
    "p, err := kafka.NewProducer(&kafka.ConfigMap{\"bootstrap.servers\": broker})\n",
    "\n",
    "doneChan := make(chan bool)\n",
    "\n",
    "go func() {\n",
    "    defer close(doneChan)\n",
    "    for e := range p.Events() {\n",
    "        switch ev := e.(type) {\n",
    "        case *kafka.Message:\n",
    "            m := ev\n",
    "            if m.TopicPartition.Error != nil {\n",
    "                fmt.Printf(\"Delivery failed: %v\\n\", m.TopicPartition.Error)\n",
    "            } else {\n",
    "                fmt.Printf(\"Delivered message to topic %s [%d] at offset %v\\n\",\n",
    "                    *m.TopicPartition.Topic, m.TopicPartition.Partition, m.TopicPartition.Offset)\n",
    "            }\n",
    "            return\n",
    "\n",
    "        default:\n",
    "            fmt.Printf(\"Ignored event: %s\\n\", ev)\n",
    "        }\n",
    "    }\n",
    "}()\n",
    "\n",
    "value := \"Hello Go!\"\n",
    "p.ProduceChannel() <- &kafka.Message{TopicPartition: kafka.TopicPartition{Topic: &topic, Partition: kafka.PartitionAny}, Value: []byte(value)}\n",
    "\n",
    "// wait for delivery report goroutine to finish\n",
    "_ = <-doneChan\n",
    "\n",
    "p.Close()\n",
    "```\n",
    "\n",
    "生产端由于kafka有消息确认机制,因此需要一个channel来获取被确认的消息,上面例子中`p.Events()`就是这样一个channel,通常我们发送归发送,监控消息发送则是另起一个go携程来做,发送我们就是直接向`p.ProduceChannel()`中丢入一个`*kafka.Message`而已.\n",
    "\n",
    "\n",
    "+ 消费端\n",
    "\n",
    "```golang\n",
    "c, err := kafka.NewConsumer(&kafka.ConfigMap{\n",
    "\t\t\"bootstrap.servers\":               broker,\n",
    "\t\t\"group.id\":                        group,\n",
    "\t\t\"session.timeout.ms\":              6000,\n",
    "\t\t\"go.events.channel.enable\":        true,\n",
    "\t\t\"go.application.rebalance.enable\": true,\n",
    "\t\t// Enable generation of PartitionEOF when the\n",
    "\t\t// end of a partition is reached.\n",
    "\t\t\"enable.partition.eof\": true,\n",
    "\t\t\"auto.offset.reset\":    \"earliest\"})\n",
    "        \n",
    "err = c.SubscribeTopics(topics, nil)\n",
    "\n",
    "\n",
    "for run == true {\n",
    "    select {\n",
    "    case sig := <-sigchan:\n",
    "        fmt.Printf(\"Caught signal %v: terminating\\n\", sig)\n",
    "        run = false\n",
    "\n",
    "    default:\n",
    "        ev :=c.Poll(100)\n",
    "        if ev == nil {\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t}\n",
    "        switch e := ev.(type) {\n",
    "        case kafka.AssignedPartitions:\n",
    "            fmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "            c.Assign(e.Partitions)\n",
    "        case kafka.RevokedPartitions:\n",
    "            fmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "            c.Unassign()\n",
    "        case *kafka.Message:\n",
    "            fmt.Printf(\"%% Message on %s:\\n%s\\n\",\n",
    "                e.TopicPartition, string(e.Value))\n",
    "        case kafka.PartitionEOF:\n",
    "            fmt.Printf(\"%% Reached %v\\n\", e)\n",
    "        case kafka.Error:\n",
    "            // Errors should generally be considered as informational, the client will try to automatically recover\n",
    "            fmt.Fprintf(os.Stderr, \"%% Error: %v\\n\", e)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "fmt.Printf(\"Closing consumer\\n\")\n",
    "c.Close()\n",
    "```\n",
    "\n",
    "消费端一样是监听`c.Poll(100)`,根据其类型进行不同的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 例子实现:\n",
    "\n",
    "+ 生产者\n",
    "\n",
    "```golang\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"math/rand\"\n",
    "\t\"os\"\n",
    "\t\"os/signal\"\n",
    "\t\"strconv\"\n",
    "\t\"sync\"\n",
    "\t\"time\"\n",
    "\n",
    "\t\"gopkg.in/confluentinc/confluent-kafka-go.v1/kafka\"\n",
    ")\n",
    "\n",
    "var csend chan os.Signal\n",
    "var cprod chan os.Signal\n",
    "var ccoll chan os.Signal\n",
    "var wg sync.WaitGroup\n",
    "\n",
    "func secondRef(p *kafka.Producer) {\n",
    "\tfmt.Println(\"secondRef | start\")\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-csend:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"secondRef | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\t\tcase e := <-p.Events():\n",
    "\t\t\tfmt.Println(\"secondRef | get event\")\n",
    "\t\t\tswitch ev := e.(type) {\n",
    "\t\t\tcase *kafka.Message:\n",
    "\t\t\t\tm := ev\n",
    "\t\t\t\tif m.TopicPartition.Error != nil {\n",
    "\t\t\t\t\tfmt.Printf(\"Delivery failed: %v\\n\", m.TopicPartition.Error)\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tfmt.Printf(\"Delivered message to topic %s [%d] at offset %v\\n\",\n",
    "\t\t\t\t\t\t*m.TopicPartition.Topic, m.TopicPartition.Partition, m.TopicPartition.Offset)\n",
    "\t\t\t\t}\n",
    "\t\t\tdefault:\n",
    "\t\t\t\tfmt.Printf(\"Ignored event: %s\\n\", ev)\n",
    "\t\t\t}\n",
    "\t\tdefault:\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"secondRef |  exit\")\n",
    "\twg.Done()\n",
    "}\n",
    "\n",
    "func producer(p *kafka.Producer, sourceQ string, exitCh string) {\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-cprod:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"Producer | get exit signal\", s)\n",
    "\t\t\tp.ProduceChannel() <- &kafka.Message{\n",
    "\t\t\t\tTopicPartition: kafka.TopicPartition{\n",
    "\t\t\t\t\tTopic:     &exitCh,\n",
    "\t\t\t\t\tPartition: kafka.PartitionAny,\n",
    "\t\t\t\t},\n",
    "\t\t\t\tValue: []byte(\"Exit\")}\n",
    "\t\t\ttime.Sleep(1 * time.Second)\n",
    "\t\t\tfmt.Println(\"Producer send msg exit to exitch\")\n",
    "\t\t\tbreak Loop\n",
    "\t\tdefault:\n",
    "\t\t}\n",
    "\t\tdata := rand.Int31n(400)\n",
    "\t\tp.ProduceChannel() <- &kafka.Message{\n",
    "\t\t\tTopicPartition: kafka.TopicPartition{\n",
    "\t\t\t\tTopic:     &sourceQ,\n",
    "\t\t\t\tPartition: kafka.PartitionAny,\n",
    "\t\t\t},\n",
    "\t\t\tValue: []byte(strconv.Itoa(int(data)))}\n",
    "\t\tfmt.Println(\"Producer send msg \", data, \" to sourceQ\")\n",
    "\t\ttime.Sleep(1 * time.Second)\n",
    "\t}\n",
    "\tfmt.Println(\"Producer |  exit\")\n",
    "\twg.Done()\n",
    "}\n",
    "\n",
    "func collector(c *kafka.Consumer, resultQ string) error {\n",
    "\terr := c.SubscribeTopics([]string{resultQ}, nil)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"collector | err\", err)\n",
    "\t\treturn err\n",
    "\t}\n",
    "\tvar sum int64 = 0\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-ccoll:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"collector | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\n",
    "\t\tcase ev := <-c.Events():\n",
    "\t\t\tswitch e := ev.(type) {\n",
    "\t\t\tcase kafka.AssignedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Assign(e.Partitions)\n",
    "\t\t\tcase kafka.RevokedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Unassign()\n",
    "\t\t\tcase *kafka.Message:\n",
    "\t\t\t\tvalue := string(e.Value)\n",
    "\t\t\t\tfmt.Printf(\"%% Message on %s:\\n%s\\n\", e.TopicPartition)\n",
    "\t\t\t\td, err := strconv.ParseInt(value, 10, 64)\n",
    "\t\t\t\tif err != nil {\n",
    "\t\t\t\t\tfmt.Println(\"collector err:\", err)\n",
    "\t\t\t\t}\n",
    "\t\t\t\tsum += d\n",
    "\t\t\t\tfmt.Println(\"collector get sum \", sum)\n",
    "\t\t\tcase kafka.PartitionEOF:\n",
    "\t\t\t\tfmt.Printf(\"%% Reached %v\\n\", e)\n",
    "\t\t\tcase kafka.Error:\n",
    "\t\t\t\t// Errors should generally be considered as informational, the client will try to automatically recover\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% Error: %v\\n\", e)\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"collector | exit\")\n",
    "\twg.Done()\n",
    "\treturn nil\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\tsourceQ := \"sourceQ\"\n",
    "\tresultQ := \"resultQ\"\n",
    "\texitCh := \"exitCh\"\n",
    "\tbroker := \"localhost:9092\"\n",
    "\tproducerConf := kafka.ConfigMap{\n",
    "\t\t\"bootstrap.servers\": broker,\n",
    "\t}\n",
    "\tconsumerConf := kafka.ConfigMap{\n",
    "\t\t\"bootstrap.servers\":               broker,\n",
    "\t\t\"group.id\":                        resultQ,\n",
    "\t\t\"session.timeout.ms\":              6000,\n",
    "\t\t\"go.events.channel.enable\":        true,\n",
    "\t\t\"go.application.rebalance.enable\": true,\n",
    "\t\t\"enable.partition.eof\":            true,\n",
    "\t\t\"auto.offset.reset\":               \"latest\"}\n",
    "\tkafkaProducer, err1 := kafka.NewProducer(&producerConf)\n",
    "\tif err1 != nil {\n",
    "\t\tpanic(err1)\n",
    "\t}\n",
    "\tkafkaConsumer, err2 := kafka.NewConsumer(&consumerConf)\n",
    "\tif err2 != nil {\n",
    "\t\tpanic(err2)\n",
    "\t}\n",
    "\tcsend = make(chan os.Signal, 1)\n",
    "\tcprod = make(chan os.Signal, 1)\n",
    "\tccoll = make(chan os.Signal, 1)\n",
    "\tsignal.Notify(ccoll, os.Interrupt, os.Kill)\n",
    "\tsignal.Notify(cprod, os.Interrupt, os.Kill)\n",
    "\tsignal.Notify(csend, os.Interrupt, os.Kill)\n",
    "\twg.Add(1)\n",
    "\tgo collector(kafkaConsumer, resultQ)\n",
    "\twg.Add(1)\n",
    "\tgo producer(kafkaProducer, sourceQ, exitCh)\n",
    "\twg.Add(1)\n",
    "\tgo secondRef(kafkaProducer)\n",
    "\twg.Wait()\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 消费者\n",
    "\n",
    "```golang\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\t\"os/signal\"\n",
    "\t\"strconv\"\n",
    "\t\"sync\"\n",
    "\n",
    "\t\"gopkg.in/confluentinc/confluent-kafka-go.v1/kafka\"\n",
    ")\n",
    "\n",
    "var csend chan os.Signal\n",
    "var cexit chan os.Signal\n",
    "var cget chan os.Signal\n",
    "var wg sync.WaitGroup\n",
    "\n",
    "func secondRef(p *kafka.Producer) {\n",
    "\tfmt.Println(\"secondRef | start\")\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-csend:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"secondRef | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\t\tcase e := <-p.Events():\n",
    "\t\t\tfmt.Println(\"secondRef | get event\")\n",
    "\t\t\tswitch ev := e.(type) {\n",
    "\t\t\tcase *kafka.Message:\n",
    "\t\t\t\tm := ev\n",
    "\t\t\t\tif m.TopicPartition.Error != nil {\n",
    "\t\t\t\t\tfmt.Printf(\"Delivery failed: %v\\n\", m.TopicPartition.Error)\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tfmt.Printf(\"Delivered message to topic %s [%d] at offset %v\\n\",\n",
    "\t\t\t\t\t\t*m.TopicPartition.Topic, m.TopicPartition.Partition, m.TopicPartition.Offset)\n",
    "\t\t\t\t}\n",
    "\t\t\tdefault:\n",
    "\t\t\t\tfmt.Printf(\"Ignored event: %s\\n\", ev)\n",
    "\t\t\t}\n",
    "\t\tdefault:\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"secondRef |  exit\")\n",
    "\twg.Done()\n",
    "}\n",
    "\n",
    "func get_result(c *kafka.Consumer, p *kafka.Producer, sourceQ string, resultQ string) error {\n",
    "\tfmt.Printf(\"get_result running\\n\")\n",
    "\terr := c.SubscribeTopics([]string{sourceQ}, nil)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"collector | err\", err)\n",
    "\t\treturn err\n",
    "\t}\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-cget:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"get_result | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\n",
    "\t\tcase ev := <-c.Events():\n",
    "\t\t\tswitch e := ev.(type) {\n",
    "\t\t\tcase kafka.AssignedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Assign(e.Partitions)\n",
    "\t\t\tcase kafka.RevokedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Unassign()\n",
    "\t\t\tcase *kafka.Message:\n",
    "\t\t\t\tvalue := string(e.Value)\n",
    "\t\t\t\tfmt.Printf(\"%% Message on %s:\\n%s\\n\", e.TopicPartition)\n",
    "\t\t\t\td, err := strconv.ParseInt(value, 10, 64)\n",
    "\t\t\t\tif err != nil {\n",
    "\t\t\t\t\tfmt.Println(\"get_result err:\", err)\n",
    "\t\t\t\t}\n",
    "\t\t\t\tresult := d * d\n",
    "\t\t\t\tp.ProduceChannel() <- &kafka.Message{\n",
    "\t\t\t\t\tTopicPartition: kafka.TopicPartition{\n",
    "\t\t\t\t\t\tTopic:     &resultQ,\n",
    "\t\t\t\t\t\tPartition: kafka.PartitionAny,\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\tValue: []byte(strconv.Itoa(int(result)))}\n",
    "\t\t\t\tfmt.Println(\"get_result send msg \", result)\n",
    "\t\t\tcase kafka.PartitionEOF:\n",
    "\t\t\t\tfmt.Printf(\"%% Reached %v\\n\", e)\n",
    "\t\t\tcase kafka.Error:\n",
    "\t\t\t\t// Errors should generally be considered as informational, the client will try to automatically recover\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% Error: %v\\n\", e)\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"get_result |  exit\")\n",
    "\twg.Done()\n",
    "\treturn nil\n",
    "}\n",
    "func listen_exit(c *kafka.Consumer, exitCh string) error {\n",
    "\tfmt.Printf(\"listen_exit running\\n\")\n",
    "\terr := c.SubscribeTopics([]string{exitCh}, nil)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Println(\"listen_exit | err\", err)\n",
    "\t\treturn err\n",
    "\t}\n",
    "Loop:\n",
    "\tfor {\n",
    "\t\tselect {\n",
    "\t\tcase s := <-cexit:\n",
    "\t\t\tfmt.Println()\n",
    "\t\t\tfmt.Println(\"listen_exit | get exit signal\", s)\n",
    "\t\t\tbreak Loop\n",
    "\t\tcase ev := <-c.Events():\n",
    "\t\t\tswitch e := ev.(type) {\n",
    "\t\t\tcase kafka.AssignedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Assign(e.Partitions)\n",
    "\t\t\tcase kafka.RevokedPartitions:\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% %v\\n\", e)\n",
    "\t\t\t\tc.Unassign()\n",
    "\t\t\tcase *kafka.Message:\n",
    "\t\t\t\tfmt.Println(\"listen_exit | get exit signal from remote----------------\")\n",
    "\t\t\t\tvalue := string(e.Value)\n",
    "\t\t\t\tfmt.Printf(\"%% Message on %s:\\n%s\\n\", e.TopicPartition)\n",
    "\t\t\t\tif value == \"Exit\" {\n",
    "\t\t\t\t\tfmt.Println(\"get exit\")\n",
    "\t\t\t\t\tcget <- os.Interrupt\n",
    "\t\t\t\t\tcsend <- os.Interrupt\n",
    "\t\t\t\t\tbreak Loop\n",
    "\t\t\t\t}\n",
    "\t\t\tcase kafka.PartitionEOF:\n",
    "\t\t\t\tfmt.Printf(\"%% Reached %v\\n\", e)\n",
    "\t\t\tcase kafka.Error:\n",
    "\t\t\t\t// Errors should generally be considered as informational, the client will try to automatically recover\n",
    "\t\t\t\tfmt.Fprintf(os.Stderr, \"%% Error: %v\\n\", e)\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\tfmt.Println(\"listen_exit |  exit\")\n",
    "\twg.Done()\n",
    "\treturn nil\n",
    "}\n",
    "func main() {\n",
    "\tbroker := \"localhost:9092\"\n",
    "\tsourceQ := \"sourceQ\"\n",
    "\tresultQ := \"resultQ\"\n",
    "\texitCh := \"exitCh\"\n",
    "\tproducerConf := kafka.ConfigMap{\n",
    "\t\t\"bootstrap.servers\": broker,\n",
    "\t}\n",
    "\tconsumerConf := kafka.ConfigMap{\n",
    "\t\t\"bootstrap.servers\":               broker,\n",
    "\t\t\"group.id\":                        resultQ,\n",
    "\t\t\"session.timeout.ms\":              6000,\n",
    "\t\t\"go.events.channel.enable\":        true,\n",
    "\t\t\"go.application.rebalance.enable\": true,\n",
    "\t\t\"enable.partition.eof\":            true,\n",
    "\t\t\"auto.offset.reset\":               \"latest\"}\n",
    "\tkafkaProducer, err1 := kafka.NewProducer(&producerConf)\n",
    "\tif err1 != nil {\n",
    "\t\tpanic(err1)\n",
    "\t}\n",
    "\tkafkaConsumer, err2 := kafka.NewConsumer(&consumerConf)\n",
    "\tif err2 != nil {\n",
    "\t\tpanic(err2)\n",
    "\t}\n",
    "\tkafkaExitConsumer, err2 := kafka.NewConsumer(&consumerConf)\n",
    "\tif err2 != nil {\n",
    "\t\tpanic(err2)\n",
    "\t}\n",
    "\tcsend = make(chan os.Signal, 1)\n",
    "\tcget = make(chan os.Signal, 1)\n",
    "\tcexit = make(chan os.Signal, 1)\n",
    "\tsignal.Notify(csend, os.Interrupt, os.Kill)\n",
    "\tsignal.Notify(cget, os.Interrupt, os.Kill)\n",
    "\tsignal.Notify(cexit, os.Interrupt, os.Kill)\n",
    "\twg.Add(1)\n",
    "\tgo get_result(kafkaConsumer, kafkaProducer, sourceQ, resultQ)\n",
    "\twg.Add(1)\n",
    "\tgo secondRef(kafkaProducer)\n",
    "\twg.Add(1)\n",
    "\tgo listen_exit(kafkaExitConsumer, exitCh)\n",
    "\twg.Wait()\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "需要注意监听退出消息的消费者和监听消息的消费者不能是同一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
